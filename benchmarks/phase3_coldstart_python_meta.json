{
  "dataset_fingerprint_file": "baselines/example_fingerprint.json",
  "generated_utc": "2026-02-08T05:21:30Z",
  "measured_runs": 1,
  "platform": {
    "machine": "arm64",
    "processor": "arm",
    "python_version": "3.13.5",
    "release": "24.6.0",
    "system": "Darwin"
  },
  "python_environment_file": "reports/python_environment.md",
  "reference_backend_file": "reports/reference_backend.md",
  "scenarios": [
    {
      "function_name": "staar_unrelated_glm",
      "kwargs": {
        "dataset": "example",
        "rare_maf_cutoff": 0.05,
        "seed": 600
      },
      "scenario_id": "staar_unrelated_glm",
      "sentinel_key": "results_STAAR_O"
    },
    {
      "function_name": "staar_related_sparse_glmmkin",
      "kwargs": {
        "dataset": "example",
        "rare_maf_cutoff": 0.05,
        "seed": 600,
        "use_precomputed_artifacts": false
      },
      "scenario_id": "staar_related_sparse_glmmkin_pure",
      "sentinel_key": "results_STAAR_O"
    },
    {
      "function_name": "staar_unrelated_binary_spa",
      "kwargs": {
        "dataset": "example",
        "rare_maf_cutoff": 0.05,
        "seed": 600
      },
      "scenario_id": "staar_unrelated_binary_spa",
      "sentinel_key": "results_STAAR_B"
    },
    {
      "function_name": "staar_related_sparse_binary_spa",
      "kwargs": {
        "dataset": "example",
        "rare_maf_cutoff": 0.05,
        "seed": 600,
        "use_precomputed_artifacts": false
      },
      "scenario_id": "staar_related_sparse_binary_spa_pure",
      "sentinel_key": "results_STAAR_B"
    },
    {
      "function_name": "staar_unrelated_glm_cond",
      "kwargs": {
        "dataset": "example",
        "rare_maf_cutoff": 0.05,
        "seed": 600
      },
      "scenario_id": "staar_unrelated_glm_cond",
      "sentinel_key": "results_STAAR_O_cond"
    },
    {
      "function_name": "indiv_score_unrelated_glm",
      "kwargs": {
        "dataset": "example",
        "rare_maf_cutoff": 0.05,
        "seed": 600
      },
      "scenario_id": "indiv_score_unrelated_glm",
      "sentinel_key": "pvalue_min"
    },
    {
      "function_name": "ai_staar_unrelated_glm",
      "kwargs": {
        "dataset": "example",
        "rare_maf_cutoff": 0.05,
        "seed": 600
      },
      "scenario_id": "ai_staar_unrelated_glm",
      "sentinel_key": "results_STAAR_O"
    },
    {
      "function_name": "ai_staar_related_sparse_glmmkin_find_weight",
      "kwargs": {
        "dataset": "example",
        "rare_maf_cutoff": 0.05,
        "seed": 600,
        "use_precomputed_artifacts": false
      },
      "scenario_id": "ai_staar_related_sparse_glmmkin_find_weight_pure",
      "sentinel_key": "results_STAAR_O"
    }
  ],
  "sentinel_checks": {
    "ai_staar_related_sparse_glmmkin_find_weight_pure.run1": 0.14369423193763015,
    "ai_staar_unrelated_glm.run1": 0.020750151319889852,
    "indiv_score_unrelated_glm.run1": 0.00028090095477744173,
    "staar_related_sparse_binary_spa_pure.run1": 0.2336048073417211,
    "staar_related_sparse_glmmkin_pure.run1": 0.13966348237712975,
    "staar_unrelated_binary_spa.run1": 0.2047522366500004,
    "staar_unrelated_glm.run1": 0.02326161035930591,
    "staar_unrelated_glm_cond.run1": 0.022907925285680412
  },
  "warmup_runs": 0
}